---
title: "Hypothesis Testing in Research Papers"
subtitle: "Guidelines for Successful Statistics with Jamovi"
author: "Damien Dupré"
date: "Dublin City University"
output:
  xaringan::moon_reader:
    css: ["default", "metropolis", "metropolis-fonts", "css/custom_design.css"]
    lib_dir: libs
    nature:
      beforeInit: "libs/cols_macro.js"
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# general options --------------------------------------------------------------
options(scipen = 999)
set.seed(123)
# chunk options ----------------------------------------------------------------
knitr::opts_chunk$set(
  cache.extra = knitr::rand_seed, 
  message = FALSE, 
  warning = FALSE, 
  error = FALSE, 
  echo = FALSE,
  cache = FALSE,
  comment = "", 
  fig.align = "center", 
  fig.retina = 3
  )
# libraries --------------------------------------------------------------------
library(emo)
library(knitr)
library(tidyverse)
library(nomnoml)
library(DiagrammeR)
library(fontawesome)
```

# Essential Concepts to Master

In academic research paper all sections are linked:

.center[**Introduction `r ji("right_arrow")` Literature Review `r ji("right_arrow")` Method `r ji("right_arrow")` Results `r ji("right_arrow")` Discussion & Conclusion**]

--

To understand the statistics in the results section it is essential to identify the concepts presented in each section:

```{nomnoml, fig.width=12, fig.height=3}
#stroke: black
#direction: right
#align: center
[Introduction | Variables]->[Literature Review | Hypotheses]
[Literature Review | Hypotheses]->[Method | Model & Equation]
[Method | Model & Equation]->[Results | Statistical Test]
[Results | Statistical Test]->[Discussion & Conclusion | Interpretation]
```

---
class: inverse, mline, center, middle

# 1. Variables

---

# Type and Role of Variables

- Is way of assigning values (numbers or characters) to labels
- Corresponds to a column in a spreadsheet

Challenge: Identify the **Role** and the **Type** of each variable

--

#### 1. Type of Variables

.pull-left[
- **Continuous**: If values are numbers
- **Categorical**: If values are characters

Note: Distinguish **Categorical Nominal** variables (*e.g.*, Irish, French) vs. **Categorical Ordinal** variables (*e.g.*, XS, S, M, L, XL)

]

.pull-right[
```{r out.width='50%'}
knitr::include_graphics("img/jamovi_icons.png")
```
]

--

#### 2. Role of Variables

A variable can have one or the other of these roles (no other role exist):

- **Outcome**: "to be explained" variable as Y (also called Dependent Variable or DV)
- **Predictor**: "doing the explaining" as X (also called Independent Variable or IV)

Note: A variable can be also both but in different hypotheses

---
class: inverse, mline, center, middle

# 2. Hypotheses

---

# Correct Hypothesis Formulation

Hypotheses are:

- Predictions supported by theory/literature
- Affirmations designed to precisely describe the relationships between variables

A hypothesis test consists of a test between two competing hypotheses:

- An alternative hypothesis $H_a$ (also called $H_1$)
- A null hypothesis $H_0$ (pronounced "H-naught")

> For $H_0$, there is no relationship between the variables. $H_a$ is the "challenger" hypothesis, it claims the existence of a relationship.

Only 2 kind of alternative hypotheses can be formulated:

- **Main Effect Hypothesis**: Relationship between 1 Predictor and 1 Outcome
- **Interaction Effect Hypothesis**: Relationship between 2+ Predictors and 1 Outcome

Challenge: **Appropriate Formulation** the hypothesis according to the type of the Predictor

---

# Correct Main Effect Hypothesis

The **Outcome has to be Continuous** but ...

- #### Case 1: Predictor is Continuous 

.small[The {**outcome**} increases when {**predictor**} {*increases/decreases/changes*}]

- #### Case 2: Predictor is Categorical (2 Categories)

.small[The {**outcome**} of {**predictor category 1**} is {*higher/lower/different*} than the {**outcome**} of {**predictor category 2**}]

- #### Case 3: Predictor is Categorical (3 or more Categories)

.small[The {**outcome**} of at least one {**predictor**} category is {*higher/lower/different*} than the other {**predictor**} categories]

---

# Correct Interaction Effect Hypothesis

The **Outcome has to be Continuous** and **whatever the Predictor 1 is** ...

- #### Case 1: Predictor 2 is Continuous

.small[The effect of {**predictor 1**} on {**outcome**} is {*higher/lower/different*} when {**predictor 2**} increases]

- #### Case 2: Predictor 2 is Categorical (2 Categories)

.small[The effect of {**predictor 1**} on {**outcome**} is {*higher/lower/different*} for {**predictor 2 category 1**} than for {**category 2**}]

- #### Case 3: Predictor 2 is Categorical (3 or more Categories)

.small[The effect of {**predictor 1**} on {**outcome**} is {*higher/lower/different*} for at least one of {**predictor 2**}]

--

#### Notes:
1. Predictor 1 and 2 are commutable (can be inverted and produce the same hypothesis)
2. An interaction effect hypothesis is also called moderation effect
3. By default, an interaction effect involves the test of the main effect hypotheses of all Predictors involved

---
class: inverse, mline, center, middle

# 3. Model & Equation

---

# Model & Equation

The basic structure of a statistical model is:

$$Outcome = Model + Error$$

where the $Model$ is a series of predictors that are expressed in hypotheses related to the same outcome.
- Main effect hypotheses are indicated with the predictor name only
- Interaction effect hypotheses are indicated with all predictor names separated by $*$

--

#### Example:

$$Outcome = Pred1 + Pred2 + Pred1 * Pred2 + Error$$

--

To evaluate their relationship with the outcome, each effect hypothesis is related with a coefficient called **Estimate** and represented with $\beta$ as follow:

$$Outcome = \beta_0 + \beta_1 Pred1 + \beta_2 Pred2 + \beta_3 Pred1 * Pred2 + Error$$

Note: $\beta_0$ is the estimate related to the intercept. It is always included, always tested but has no interest in the analysis

---

# Evaluation of the Significance

Testing for the significance of the effect means evaluating if this estimate $\beta$ value is significantly **different, higher or lower than 0** as hypothesised in $H_a$:

- $\beta \neq 0$ means our hypothesis doesn't precise the direction of the change, just that there is a change
- $\beta > 0$ means our hypothesis indicates that the relationship increases or a group is higher than another group
- $\beta < 0$ means our hypothesis indicates that the relationship decreases or a group is lower than another group

Note: $H_0$ will always predict that $\beta = 0$

--

The significance, called $p$-value, is the probability to consider $H_0$ as True. This probability is between 0% and 100% which corresponds to a value between 0.0 and 1.0.

If the $p$-value:

- Is **higher** than 5% or 0.05, then $H_0$ is **accepted**
- Is **lower** than 5% or 0.05, then $H_0$ is **rejected** and $H_a$ is considered as plausible

---

# Model & Equation

A graphic representation of the model's hypothesised effects can be done:
- All the arrows correspond to an hypothesis to be tested
- All the tested hypotheses have to be represented with an arrow

.pull-left[
.center[**A simple arrow is a main effect**]

```{r eval=TRUE}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  Predictor; Outcome
        
  Predictor -> Outcome [label= β1]
}
", width = 400, height = 200)
```

]

.pull-right[

.center[**A crossing arrow is an interaction effect**]

```{r}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    'Predictor 1'; Outcome; 'Predictor 2'
    node [shape = point, width = 0, height = 0]
    ''
    
    'Predictor 2' -> '' [label= β2]
    'Predictor 1' -> '' [arrowhead = none] [label= β1]
    ''-> Outcome [label= β3]
    
    subgraph {
      rank = same; 'Predictor 2'; '';
    }
  }", height = 200, width = 400)
```

.center[Note: By default, an interaction effect involves the test of the main effect hypotheses of all Predictors involved]

]

---
class: inverse, mline, center, middle

# 4. Statistical Test

---

# JAMOVI: Stats. Open. Now.

- Can be downloaded or used online on https://www.jamovi.org/
- Book "Learning Statistics with Jamovi" free here: https://www.learnstatswithjamovi.com/

Advantages:
1. Free
2. Simple Interface
3. No Missing Values to Declare
4. No Variable to Recode by Default
5. Ready to Publish Tables and Figures
6. Free Modules for Advanced Statistics (Mediation, Generalized LM, Linear Mixed Model)

Note: In Jamovi ...
- The outcome is called Dependent Variable
- A continuous predictor is a covariate
- A categorical predictor is a factor

---
class: title-slide, middle

## 4.1 Hypotheses with Continuous Predictors and with Categorical Predictors Having 2 Categories

---

# Hypothesis Testing

1. Open your file
2. Check the type of your variables
3. **Analyses** > **Regression** > **Linear Regression**
4. Set the Outcome as DV and 
  - **To test the main effect hypotheses**: set the Predictors as Covariates/Factors
  - **To test interaction effect hypotheses**: In Model Builder, select all predictor with `CTRL` (win) or `Command` (mac) and bring them as interaction in the model
  
--
  
Communicate the Results about the full model and each hypothesis:

--

- Use **Model Fit Measure Table** to evaluate the accuracy of the full model

The predictions from a model including all effects are significant/not-significant better than without these effects ( $R^2 = value_{R^2}$, $F(df1,df2) = value_{F}$, $p = value_{p}$)

--

- Use **Model Coefficients Table** to conclude about each hypothesis

The effect of $Predictor$ on $Outcome$ is statistically significant/not-significant, therefore $H_0$ can be rejected/accepted ( $b = value_{estimate}, 95\% CI [lower\,CI, upper\,CI]$, $t(df) = value_t$, $p = value_{p}$).

---
class: title-slide, middle

## 4.2 Hypotheses with Categorical Predictors Having 3 or more Categories

---

# Hypothesis Testing

1. Open your file
2. Check the type of your variables
3. **Analyses** > **Regression** > **Linear Regression**
4. Set the Outcome as DV and 
  - **To test the main effect hypotheses**: set the Predictors as Factors
  - **To test interaction effect hypotheses**: In Model Builder options, select all predictor with `CTRL` (win) or `Command` (mac) and bring them as interaction in the model
5. Tick **ANOVA Test** in Model Coefficient options
  
--
  
Communicate the Results about the full model and each hypothesis:

--

- Use **Model Fit Measure Table** to evaluate the accuracy of the full model

The predictions from a model including all effects are significant/not-significant better than without these effects ( $R^2 = value_{R^2}$, $F(df1,df2) = value_{F}$, $p = value_{p}$)

- Use **Omnibus ANOVA Test Table** to conclude about each hypothesis

The effect of $Predictor$ on $Outcome$ is statistically significant/not-significant, therefore $H_0$ can be rejected/accepted ( $F(df_{predictor}, df_{residual}) = value_F$, $p = value_{p}$).

---
class: inverse, mline, center, middle

# 5. Discussion & Conclusion

---

# Interpret the Analyses

From here...
- There is no number to be shown and no specific guidelines
- Correct interpretation comes if results have been understood and if reasons for the results to be the ones obtained have been identified

```{r out.width='40%'}
include_graphics("https://pbs.twimg.com/media/EhjV0v-XgAEh2pk?format=jpg&name=large")
```


---
class: inverse, mline, left, middle

<img class="circle" src="https://github.com/damien-dupre.png" width="250px"/>

# Thanks for your attention and don't hesitate if you have any question!

[`r fa(name = "twitter")` @damien_dupre](http://twitter.com/damien_dupre)  
[`r fa(name = "github")` @damien-dupre](http://github.com/damien-dupre)  
[`r fa(name = "link")` damien-datasci-blog.netlify.app](https://damien-datasci-blog.netlify.app)  
[`r fa(name = "paper-plane")` damien.dupre@dcu.ie](mailto:damien.dupre@dcu.ie)