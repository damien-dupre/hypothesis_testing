---
title: "Hypothesis Testing in Research Papers"
subtitle: "Guidelines for Successful Statistics with Jamovi"
author: "Damien Dupré"
date: "Dublin City University"
output:
  xaringan::moon_reader:
    css: ["default", "metropolis", "metropolis-fonts", "css/custom_design.css"]
    lib_dir: libs
    nature:
      beforeInit: "libs/cols_macro.js"
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# libraries --------------------------------------------------------------------
library(anicon)
library(DiagrammeR)
library(emo)
library(fontawesome)
library(knitr)
library(nomnoml)
library(plotly)
library(tidyverse)

# general options --------------------------------------------------------------
options(scipen = 999)
set.seed(123)
# chunk options ----------------------------------------------------------------
opts_chunk$set(
  cache.extra = rand_seed, 
  message = FALSE, 
  warning = FALSE, 
  error = FALSE, 
  echo = FALSE,
  cache = FALSE,
  comment = "", 
  fig.align = "center", 
  fig.retina = 3
  )

# functions --------------------------------------------------------------------
rtruncnorm <- function(N, mean = 0, sd = 1, a = -Inf, b = Inf) {
  U <- runif(N, pnorm(a, mean, sd), pnorm(b, mean, sd))
  qnorm(U, mean, sd) 
}

# data -------------------------------------------------------------------------
df_data <- 
  tibble(
    predictor = rtruncnorm(100, mean = 5, sd = 2.5, a = 0, b = 10),
    outcome = 2 + 0.9 * predictor + rnorm(100, mean = 0, sd = 1)
  )

df_lm <- lm(outcome ~ predictor, df_data)

df_data <- df_data %>% 
  mutate(
    b0 = rnorm(100, df_lm$coefficients[["(Intercept)"]], 4),
    b1 = rnorm(100, df_lm$coefficients[["predictor"]], 1)
  )
```

# Essential Concepts to Master

In academic research paper all sections are linked:

.center[**Introduction `r ji("right_arrow")` Literature Review `r ji("right_arrow")` Method `r ji("right_arrow")` Results `r ji("right_arrow")` Discussion & Conclusion**]

--

To understand the statistics in the results section it is essential to identify the concepts presented in each section:

```{nomnoml, fig.width=12, fig.height=3}
#stroke: black
#direction: right
#align: center
[Introduction | Variables]->[Literature Review | Hypotheses]
[Literature Review | Hypotheses]->[Method | Model & Equation]
[Method | Model & Equation]->[Results | Statistical Test]
[Results | Statistical Test]->[Discussion & Conclusion | Interpretation]
```

---
class: inverse, mline, center, middle

# 1. Variables

---

# Type and Role of Variables

- Is way of assigning values (numbers or characters) to labels
- Corresponds to a column in a spreadsheet

`r faa("star", animate="burst", speed="slow", color="orange")` Challenge: Identify the **Type** and the **Role** of each variable

--

#### 1. Type of Variables

.pull-left[
- **Continuous**: If values are numbers
- **Categorical**: If values are characters

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: Distinguish **Categorical Nominal** variables (*e.g.*, Irish, French) vs. **Categorical Ordinal** variables (*e.g.*, XS, S, M, L, XL)

]

.pull-right[
```{r out.width='50%'}
include_graphics("img/jamovi_icons.png")
```
]

--

#### 2. Role of Variables

A variable can have one or the other of these roles (no other role exist):

- **Outcome**: "to be explained" variable as Y (also called Dependent Variable or DV)
- **Predictor**: "doing the explaining" as X (also called Independent Variable or IV)

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: A variable can be also both but in different hypotheses

---
class: inverse, mline, center, middle

# 2. Hypotheses

---

# Correct Hypothesis Formulation

Hypotheses are:

- Predictions supported by theory/literature
- Affirmations designed to precisely describe the relationships between variables

A hypothesis test consists of a **test between two competing hypotheses**:

- An alternative hypothesis $H_a$ (also called $H_1$)
- A null hypothesis $H_0$ (pronounced "H-naught" or "H-zero")

> For $H_0$, there is no relationship between the variables. $H_a$ is the "challenger" hypothesis, it claims the existence of a relationship.

--

Only 2 kind of alternative hypotheses can be formulated:

- **Main Effect Hypothesis**: Relationship between 1 Predictor and 1 Outcome
- **Interaction Effect Hypothesis**: Relationship between 2+ Predictors and 1 Outcome

`r faa("star", animate="burst", speed="slow", color="orange")` Challenge: **Appropriate Formulation** the hypothesis according to the type of the Predictor

---

# Correct Main Effect Hypothesis

The **Outcome has to be Continuous** but ...

--

- Case 1: Predictor is Continuous 

#### .center[The {**outcome**} increases when {**predictor**} changes]

--

- Case 2: Predictor is Categorical (2 Categories)

#### .center[The average {**outcome**} for {**predictor category 1**} is different than the average {**outcome**} for {**predictor category 2**}]

--

- Case 3: Predictor is Categorical (3 or more Categories)

#### .center[The average {**outcome**} for at least one {**predictor**} category is different from the average {**outcome**} for the other {**predictor**} categories]

---

# Correct Interaction Effect Hypothesis

The **Outcome has to be Continuous** and **whatever the Predictor 1 is** ...

--

- Case 1: Predictor 2 is Continuous

#### .center.big[The effect of {**predictor 1**} on {**outcome**} changes when {**predictor 2**} increases]

--

- Case 2: Predictor 2 is Categorical (2 Categories)

#### .center[The effect of {**predictor 1**} on {**outcome**} for {**predictor 2 category 1**} is different from the effect of {**predictor 1**} on {**outcome**} for {**predictor 2 category 2**}]

--

- Case 3: Predictor 2 is Categorical (3 or more Categories)

#### .center[The effect of {**predictor 1**} on {**outcome**} for at least one of {**predictor 2**} category is different from the effect of {**predictor 1**} on {**outcome**} for the other {**predictor 2**} categories]

--

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Notes:
1. Predictor 1 and 2 are commutable (can be inverted and produce the same hypothesis)
2. An interaction effect hypothesis is also called moderation effect
3. By default, an interaction effect involves the test of the main effect hypotheses of all Predictors involved

---

# Special Hypotheses Formulation

- Mediation Effect Hypothesis

The mediation model is a path analysis which involves 3 different linear models but only one of them is the test of the mediation:

#### .center[The {**outcome**} increases when {**predictor**} changes]

#### .center[The {**mediator**} increases when {**predictor**} changes]

#### .center[The effect of {**predictor**} on {**outcome**} is explained by {**mediator**}]

--

- Structural Equation Model Effect Hypotheses

A SEM is a path analysis containing only main effect hypotheses (no interaction or mediation possible) but with multiple Outcome and Predictor variables:

#### .center[Use the formulation templates for main effect hypotheses]

---
class: inverse, mline, center, middle

# 3. Model Equation

---

# Model & Equation

The basic structure of a statistical model is:

$$Outcome = Model + Error$$

where the $Model$ is a series of predictors that are expressed in hypotheses related to the same outcome.
- Main effect hypotheses are indicated with the predictor name only
- Interaction effect hypotheses are indicated with all predictor names separated by $*$

--

#### Example:

$$Outcome = Pred1 + Pred2 + Pred1 * Pred2 + Error$$

--

To evaluate their relationship with the outcome, each effect hypothesis is related with a coefficient called **Estimate** and represented with $b$ as follow:

$$Outcome = b_0 + b_1/,Pred1 + b_2/,Pred2 + b_3/,Pred1 * Pred2 + Error$$

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: $b_0$ is the estimate related to the intercept. It is always included, always tested but has no interest in the analysis

---
class: inverse

# The Estimate $b$

.pull-left[
To find the **Estimate** for the intercept and each predictor, all possible lines are calculated and the one with the lowest amount of error is selected
]

.pull-right[
```{r fig.width=5, fig.height=3}
ggplot(df_data, aes(predictor, outcome)) + 
  geom_abline(aes(intercept = b0, slope = b1), alpha = 1/4) +
  geom_point() +
  scale_x_continuous(breaks = c(0, seq(0:10)), limits = c(0, 10)) +
  scale_y_continuous(limits = c(0, 10)) +
  theme(
    # axis.text.x = element_blank(), 
    # axis.text.y = element_blank(),
    text = element_text(size = 20)
  )
```
]

.pull-left[
The **Estimate of the Intercept** corresponds to the value of the Outcome when the Predictor is $0$.

The **Estimate of each Predictor** corresponds to how many units the Outcome increases when the Predictor increase by $1$ unit (slope of the line).

]

.pull-right[
```{r fig.width=5, fig.height=3}
ggplot(df_data, aes(predictor, outcome)) +
  geom_point(color = "gray", size = 2, alpha = 0.5) +
  geom_smooth(method = "lm", fullrange = TRUE, se = FALSE) +
  geom_hline(yintercept = df_lm$coefficients[["(Intercept)"]], color = 'black', size = 0.5, linetype = 'dotted') +
  annotate("text", x = 8, y = df_lm$coefficients[["(Intercept)"]] + 0.5, label = "Intercept Estimate b0") +
  annotate('segment', x = 1, xend = 2, y = df_lm$coefficients[["(Intercept)"]] + 1*df_lm$coefficients[["predictor"]], yend = df_lm$coefficients[["(Intercept)"]] + 1*df_lm$coefficients[["predictor"]], color = 'red') +
  annotate('segment', x = 2, xend = 2, y = df_lm$coefficients[["(Intercept)"]] + 1*df_lm$coefficients[["predictor"]], yend = df_lm$coefficients[["(Intercept)"]] + 2*df_lm$coefficients[["predictor"]], color = 'red') +
  annotate("text", x = 4, y = df_lm$coefficients[["(Intercept)"]] + 1.5*df_lm$coefficients[["predictor"]], label = "Predictor Estimate b1") +
  scale_x_continuous(breaks = c(0, seq(0:10)), limits = c(0, 10)) +
  scale_y_continuous(limits = c(0, 10)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```

]

---

class: inverse

# The Standardized Estimate

.pull-left[
Estimates can't be compared because they usually have different units. However, once standardized ([centred around $0$ with a covariance of $1$](https://en.wikipedia.org/wiki/Standardized_coefficient)), these standardized estimates can be compared. 

**Standardized Estimates also corresponds to the correlation** between the Outcome and the Predictor (i.e., ranges from $\text{-}1$ to $1$ with $0$ being no relationship).

Testing $H_a\,vs\,H_0$ is the exact same thing when using the obtained Estimate or the Standardized Estimate.

However, having a high or low (Standardized) Estimate doesn't mean significant effect.
]

.pull-right[

```{r fig.width=5.5, fig.height=7.4}
df_data <- 
  tibble(
    predictor = rtruncnorm(100, mean = 0, sd = 2.5, a = -5, b = 5),
    outcome = 0.9 * predictor + rnorm(100, mean = 0, sd = 1)
  ) %>% 
  mutate(
    b1 = 0.9
  )

df_data_null <- df_data %>% 
  mutate(
    outcome = rnorm(100, mean = 0, sd = 1),
    b1 = 0
  )

df_data_inverse <- df_data %>% 
  mutate(
    outcome = (max(outcome) + min(outcome)) - outcome,
    b1 = -round(df_lm$coefficients[["predictor"]], 1)
  )

df_data_almost <- df_data %>% 
  mutate(
    outcome = 0.5 * predictor + rnorm(100, mean = 0, sd = 1),
    b1 = 0.5
  )

df_data_almost_inverse <- df_data_almost %>% 
  mutate(
    outcome = (max(outcome) + min(outcome)) - outcome,
    b1 = -0.5
  )

df_data %>% 
  bind_rows(
    df_data_null, 
    df_data_inverse, 
    df_data_almost, 
    df_data_almost_inverse
  ) %>%
  filter(outcome < 10) %>%
  plot_ly(x = ~predictor, y = ~outcome) %>%
  add_markers(color = ~b1, frame = ~b1, ids = ~predictor) %>%
  hide_colorbar() %>%
  animation_opts(frame = 1000, easing = "linear") %>%
  animation_slider(
    currentvalue = list(prefix = "Standardized Estimate ", font = list(color = "red"))
  )

```

]

---

# Evaluation of the Significance

Testing for the significance of the effect means evaluating if this estimate $b$ value is significantly **different than 0** as stated in the alternative hypothesis $(H_a:b \neq 0)$ 

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: $H_0$ will always predict that $b = 0$

--

The statistical significance of an effect estimate depends on the **strength of the relationship** and on the **sample size**:

- An estimate of $b_1 = 0.02$ can be very small but still significantly different from $b_1 = 0$
- Whereas an estimate of $b_1 = 0.35$ can be stronger but in fact not significantly different from $b_1 = 0$

--

The significance, called $p$-value, is the probability to consider $H_0$ as True. This probability is between 0% and 100% which corresponds to a value between 0.0 and 1.0.

If the $p$-value:

- Is **higher** than 5% or 0.05, then $H_0$ is **accepted**
- Is **lower** than 5% or 0.05, then $H_0$ is **rejected** and $H_a$ is considered as plausible

---

# Mediation Equations

A mediation analysis is comprised of **three sets of regression**: $Predictor$ → $Outcome$, $Predictor$ → $Mediator$, and $Predictor$ + $Mediator$ → $Outcome$. They are just three regression analyses!

--

#### Requirement 1. $Outcome = b_{0} + b_{1}\,Predictor + e$

Is $b_{1}$ significant? We want $Predictor$ to affect $Outcome$ (Direct Effect). If there is no relationship between $Predictor$ and $Outcome$, there is nothing to mediate.

--

#### Requirement 2. $Mediator = b_{0} + b_{2}\,Predictor + e$

Is $b_{2}$ significant? We want $Predictor$ to affect $Mediator$. If $Predictor$ and $Mediator$ have no relationship, $Mediator$ is just a third variable that may or may not be associated with $Outcome$. A mediation makes sense only if $Predictor$ affects $Mediator$.

--

#### Proper test. $Outcome = b_{0} + b_{4}\,Predictor + b_{3}\,Mediator + e$

Is $b_{4}$ non-significant or smaller than before? We want $Mediator$ to affect $Outcome$, but $Predictor$ to no longer affect $Outcome$ (or $Predictor$ to still affect $Outcome$ but in a smaller magnitude).

---

# Structural Equation Model Equations

#### A Confirmatory Factorial Analysis is performed for each latent variable

$Variable\,1 = \alpha_1\,Item1 + \alpha_2\,Item2 + \alpha_3\,Item3 + \alpha_4\,Item4 + \epsilon$
$Variable\,2 = \alpha_5\,Item5 + \alpha_6\,Item6 + \alpha_7\,Item7 + \alpha_8\,Item8 + \epsilon$
$Variable\,3 = \alpha_9\,Item9 + \alpha_{10}\,Item10 + \alpha_{11}\,Item11 + \epsilon$

--

#### A Linear Regression is performed for each outcome variable

$Variable\,2 = b_0 + b_1\,Variable\,1 + e$
$Variable\,3 = b_0 + b_1\,Variable\,1 + b_2\,Variable\,2 + e$

Here, the linear regression between the latent variables are testing the model's hypotheses

--

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: SEM Variables can be used as Predictor and as Outcome Variables but in different equations (see $Variable\,2$ here above) 

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: Testing Interaction and Mediation hypotheses in SEM is controversial, avoid them in SEM as much as you can

---
class: inverse, mline, center, middle

# 4. Model Representation

---

# Representing a Model

A graphic representation of the model's hypothesised effects can be done:
- All the arrows correspond to an hypothesis to be tested
- All the tested hypotheses have to be represented with an arrow

.pull-left[
.center[**A simple arrow is a main effect**]

```{r eval=TRUE}
grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  Predictor; Outcome
        
  Predictor -> Outcome [label= b1]
}
", width = 400, height = 200)
```

]

.pull-right[

.center[**A crossing arrow is an interaction effect**]

```{r}
grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    'Predictor 1'; Outcome; 'Predictor 2'
    node [shape = point, width = 0, height = 0]
    ''
    
    'Predictor 2' -> '' [label= b2]
    'Predictor 1' -> '' [arrowhead = none] [label= βb1]
    ''-> Outcome [label= b3]
    
    subgraph {
      rank = same; 'Predictor 2'; '';
    }
  }", height = 200, width = 400)
```

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: By default, an interaction effect involves the test of the main effect hypotheses of all Predictors involved
]

---

# Special Model Representation

.pull-left[
### Simple Mediation Model

```{r}
grViz("
  digraph {
    graph [rankdir = LR]
  
    node []
    Predictor; Mediator; Outcome
    
    Predictor -> {Mediator Outcome}
    Mediator -> Outcome

  }", width = 400, height = 300)
```

`r faa("arrow-circle-right", animate="horizontal", speed="slow", color="blue")` Note: More complex Mediation models are possible involving interaction with control variables and muliple mediators, see for example https://jamovi-amm.github.io/glm_example2.html
]

.pull-right[
### Structural Equation Model

```{r}
grViz("
digraph rmarkdown {
  graph [splines = no; rankdir = LR]
  
  node [shape = oval]
  'Variable 1'; 'Variable 2'; 'Variable 3'
  
  node [shape = box]
  'Item 1', 'Item 2', 'Item 3', 'Item 4', 'Item 5', 'Item 6', 'Item 7', 'Item 8', 'Item 9', 'Item 10', 'Item 11'
  
  {'Item 1' 'Item 2' 'Item 3' 'Item 4'} -> 'Variable 1' [arrowhead = none]
  {'Item 5' 'Item 6' 'Item 7' 'Item 8'} -> 'Variable 2' [arrowhead = none]
  {'Item 9' 'Item 10' 'Item 11'} -> 'Variable 3' [arrowhead = none]
  
  'Variable 1' -> {'Variable 2' 'Variable 3'}
  'Variable 2' -> 'Variable 3'

  subgraph {
      rank = same; 'Variable 1'; 'Variable 2';
  }
  
  subgraph {
      rank = same; 'Item 1'; 'Item 2'; 'Item 3'; 'Item 4'; 'Item 5'; 'Item 6'; 'Item 7'; 'Item 8';
  }

}
")
```
]

---
class: inverse, mline, center, middle

# 5. Statistical Test

---

# JAMOVI: Stats. Open. Now.

Jamovi is a statistical spreadsheet software designed to be **easy to use**. Jamovi is a compelling alternative to costly statistical products such as SPSS, SAS and JMP to cite a few.

Jamovi will always be **free and open** because Jamovi is made by the scientific community, for the scientific community.

- It can be **downloaded from its website** https://www.jamovi.org/
- It can also be **used without installation**, in a web browser, https://cloud.jamovi.org/ for **online demo** but this demo undergoes periods of downtime, and may cease functioning (without warning) at any time.

`r faa("exclamation-triangle", animate="flash", speed="slow", color="red")` Book "Learning Statistics with JAMOVI" free here: https://www.learnstatswithjamovi.com/

```{r out.width='100%'}
include_graphics("https://www.jamovi.org/assets/header-logo.svg")
```

---

# Good Practices with Hypothesis Testing

- All hypotheses using the **same Outcome variable have to be tested in the same model** and not separately.

- Even if available, no need to use t-tests or ANOVA separate modules because the **Linear Regression can test all types of hypothesis**.

- **Do not use a correlation matrix to test your hypotheses**, they are exculively dedicated to evaluate correlations between predictors.

- A $p$-value never equals $0$, **round to $p < .001$ if lower than $0.001$**.

- Despite never shown in academic papers, the **4 conditions of applications for Linear Model should always be checked**:
  - Linearity of the relationship,
  - Normal distribution of the residuals,
  - Homogeneity of the residuals,
  - Independance of observations.

---
class: title-slide, middle

## 5.1 Hypotheses with Continuous Predictors and with Categorical Predictors Having 2 Categories

---

# Hypothesis Testing

1. Open your file
2. Check the type of your variables
3. **Analyses** > **Regression** > **Linear Regression**
4. Set the Outcome as DV and 
  - **To test the main effect hypotheses**: set the Predictors as Covariates/Factors
  - **To test interaction effect hypotheses**: In Model Builder, select all predictor with `CTRL` (win) or `Command` (mac) and bring them as interaction in the model
  
--
  
Communicate the Results about the full model and each hypothesis:

--

- Use **Model Fit Measure Table** to evaluate the accuracy of the full model

The predictions from a model including all effects are significant/not-significant better than without these effects $(R^2 = value_{R^2}$, $F(df1,df2) = value_{F}$, $p = value_{p})$

--

- Use **Model Coefficients Table** to conclude about each hypothesis

The effect of $Predictor$ on $Outcome$ is statistically significant/not-significant, therefore $H_0$ can be rejected/accepted $(b = value_{estimate}, 95\% CI [lower\,CI, upper\,CI]$, $t(df2) = value_t$, $p = value_{p})$.

---
class: title-slide, middle

## 5.2 Hypotheses with Categorical Predictors Having 3 or more Categories

---

# Hypothesis Testing

1. Open your file
2. Check the type of your variables
3. **Analyses** > **Regression** > **Linear Regression**
4. Set the Outcome as DV and 
  - **To test the main effect hypotheses**: set the Predictors as Factors
  - **To test interaction effect hypotheses**: In Model Builder options, select all predictor with `CTRL` (win) or `Command` (mac) and bring them as interaction in the model
5. Tick **ANOVA Test** in Model Coefficient options
  
--
  
Communicate the Results about the full model and each hypothesis:

--

- Use **Model Fit Measure Table** to evaluate the accuracy of the full model

The predictions from a model including all effects are significant/not-significant better than without these effects $(R^2 = value_{R^2}$, $F(df1,df2) = value_{F}$, $p = value_{p})$

- Use **Omnibus ANOVA Test Table** to conclude about each hypothesis

The effect of $Predictor$ on $Outcome$ is statistically significant/not-significant, therefore $H_0$ can be rejected/accepted $(F(df_{predictor}, df_{residual}) = value_F$, $p = value_{p})$.

---

# Mediation Analysis in Jamovi

In Jamovi it is possible to do all steps at once using the **jAMM module** (Jamovi Advanced Mediation Models)

To do it, install the **jAMM module** by clicking on the cross "Modules" at top right corner > Jamovi library.

Then follow the example described here: https://jamovi-amm.github.io/glm_example1.html

```{r out.width='70%'}
include_graphics("https://jamovi-amm.github.io/glm/main.png")
```

---

# SEM Analysis in Jamovi

In Jamovi it is possible to run an SEM either by coding with Lavaan syntax (https://lavaan.ugent.be/) or by using an user friendly interface with the **SEMLj module**

To do it, install the **SEMLj module** by clicking on the cross "Modules" at top right corner > Jamovi library.

Then follow the example described here: https://semlj.github.io/example2.html

```{r out.width='70%'}
include_graphics("https://semlj.github.io/pics/overview.png")
```

---
class: inverse, mline, center, middle

# 6. Discussion & Conclusion

---

# Interpret the Analyses

From here...

- There is no number to be shown and no specific guidelines
- Correct interpretation comes if results have been understood and if reasons for the results to be the ones obtained have been identified

```{r out.width='40%'}
include_graphics("https://pbs.twimg.com/media/EhjV0v-XgAEh2pk?format=jpg&name=large")
```

---
class: inverse, mline, center, middle

# 7. Live Demo

---
class: inverse, mline, left, middle

<img class="circle" src="https://github.com/damien-dupre.png" width="250px"/>

# Thanks for your attention and don't hesitate to ask if you have any question!

[`r fa(name = "twitter")` @damien_dupre](http://twitter.com/damien_dupre)  
[`r fa(name = "github")` @damien-dupre](http://github.com/damien-dupre)  
[`r fa(name = "link")` damien-datasci-blog.netlify.app](https://damien-datasci-blog.netlify.app)  
[`r fa(name = "paper-plane")` damien.dupre@dcu.ie](mailto:damien.dupre@dcu.ie)